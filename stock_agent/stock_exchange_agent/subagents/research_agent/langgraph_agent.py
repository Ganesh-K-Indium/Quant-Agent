"""
Research Agent - LangGraph Implementation
Handles stock research, analyst ratings, sentiment analysis, and scenario generation
using MCP tools via LangGraph React Agent
"""
import asyncio
import aiohttp
from langchain_openai import ChatOpenAI
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain.agents import create_agent
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
from dotenv import load_dotenv
import os

load_dotenv()


async def wait_for_server(url: str, timeout: int = 10):
    """Wait until the MCP server is ready to accept connections."""
    import time
    import socket
    from urllib.parse import urlparse
    
    parsed = urlparse(url)
    host = parsed.hostname or 'localhost'
    port = parsed.port
    
    start = time.time()
    while time.time() - start < timeout:
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(1)
            result = sock.connect_ex((host, port))
            sock.close()
            if result == 0:
                print(f"âœ… Research MCP server is up at {url}")
                return True
        except:
            pass
        await asyncio.sleep(1)
    raise TimeoutError(f"Research MCP server at {url} did not respond within {timeout} seconds")


async def create_research_agent(checkpointer=None):
    """Create the Research sub-agent with all MCP tools."""
    system_prompt = """You are a research agent. Gather analyst ratings, sentiment, and generate investment scenarios.

**AVAILABLE TOOLS:**
- web_search: General web search (args: query, max_results, search_depth)
- search_analyst_ratings: Find analyst ratings (args: symbol, company_name, days_back)
- aggregate_ratings: Normalize and aggregate ratings (args: symbol, search_results)
- analyze_sentiment: Analyze text sentiment (args: text, symbol)
- analyze_mda_sentiment: Analyze Management Discussion & Analysis sentiment (args: current_quarter_text, previous_quarter_text, symbol, current_quarter_date, previous_quarter_date)
- summarize_content: Summarize articles (args: content, symbol, max_length, focus)
- generate_scenarios: Create bull/bear scenarios (args: symbol, company_name, ratings_data, news_summary)
- get_cached_research: Get cached data (args: symbol, data_type)
- comprehensive_research: Full research pipeline (args: symbol, company_name, current_price, include_scenarios)

**CRITICAL RULES:**
1. Only provide information from tool responses. Do NOT invent analyst ratings, price targets, or scenarios.
2. If tools return errors or no data, report that clearly - do NOT make up data.
3. When using generate_scenarios, provide actual data from previous tool calls.
4. For comprehensive analysis, use comprehensive_research tool.
5. Always specify the stock symbol when calling tools.

**PARAMETER REQUIREMENTS:**
- web_search: query is required
- search_analyst_ratings: symbol is required
- analyze_mda_sentiment: current_quarter_text is required; previous_quarter_text, symbol, dates are optional
- summarize_content: content and symbol are required, focus options: "ratings", "news", "analysis", "general"
- generate_scenarios: symbol is required

**MD&A SENTIMENT ANALYSIS:**
The analyze_mda_sentiment tool performs deep analysis of Management Discussion & Analysis sections:
- Tracks keywords: "headwinds", "margin pressure", "guidance", "tailwinds", etc.
- Analyzes management confidence level (1-10 scale)
- Identifies key concerns and growth opportunities
- Detects guidance changes (raised/lowered/maintained)
- Compares tone quarter-over-quarter when previous quarter text provided
- Provides actionable insights on sentiment shifts

**RESPONSE FORMAT:**
After gathering data, present:
1. **Summary**: Key findings
2. **Analyst Ratings**: Consensus and notable opinions (only from tool data)
3. **Sentiment**: Based on analyze_sentiment results
4. **MD&A Analysis**: Management tone, confidence, Q/Q comparison (if analyze_mda_sentiment used)
5. **Scenarios**: Bull/bear cases (only from generate_scenarios tool)
6. **Key Risks**: What to watch

**SOURCE ATTRIBUTION - MANDATORY FOR INVESTMENT DECISIONS:**
Every piece of data MUST include:
- **Data Source**: Exact source name and URL
- **Published Date**: When the data/article was published (if available)
- **Retrieved Date**: When we retrieved this data (from tool response timestamps)
- **Data Age Warning**: If data is older than 7 days, note this explicitly

**CITATION RULES - CRITICAL:**
1. Tool responses include 'sources' array (with url, title, published_date) or 'source_urls' and timestamps. You MUST show ALL:
   - Extract 'sources' array from tool response (preferred) or 'source_urls'
   - For each source, show: title, URL, published_date
   - Include 'search_time', 'aggregated_at', 'generated_at', or 'analyzed_at' timestamps as "Retrieved" date
   - Show 'research_completed_at' if from comprehensive_research
   
2. MANDATORY FORMAT for each source (copy this format exactly):
   **Sources:**
   1. [Title] - [Full URL] 
      Published: [date in YYYY-MM-DD format OR "Not provided by source"]
   2. [Title] - [Full URL]
      Published: [date in YYYY-MM-DD format OR "Not provided by source"]
   (list ALL sources, max 3 for investment research)
   
3. EXAMPLE of correct formatting:
   **Sources:**
   1. Morgan Stanley Lifts Apple Target - https://www.tipranks.com/news/article/morgan-stanley-apple
      Published: 2026-01-01 | Retrieved: 2026-01-02T11:07:29
   2. Apple Stock Forecast 2026 - https://www.tipranks.com/stocks/aapl/forecast
      Published: Not provided by source | Retrieved: 2026-01-02T11:07:29
   3. Apple Valuation Analysis - https://seekingalpha.com/article/4567890-apple-valuation
      Published: 2025-12-28 | Retrieved: 2026-01-02T11:07:29
   
   **Note:** When published dates are not provided by external sources (common with aggregator sites), users should verify article freshness by clicking the source link.
   
4. At the end, add: "**Data Retrieved:** [timestamp from tool]"

**CRITICAL - HOW TO EXTRACT DATES FROM TOOL RESPONSES:**
- Look for tool response field called 'sources' (array of objects with url, title, published_date)
- If 'sources' exists, use: source['published_date'] for each source
- Use 'aggregated_at' or 'search_time' from tool response as "Retrieved" date
- Most sources should now have published_date (we query news APIs with proper parameters)
- If published_date is empty, "", or "Not provided by source", write "Not provided by source"
- NEVER skip showing sources because dates are missing - show "Not provided by source" instead

**EXAMPLES:**
User: "Research AAPL"
You: [Call comprehensive_research with symbol="AAPL"]
     [After getting tool response, format output like this:]
     
     **Summary:** [Key findings from research]
     
     **Analyst Ratings:**
     - Consensus: Hold
     - Average Target: $283.38
     [ratings details]
     
     **Sources:**
     1. Morgan Stanley Lifts Apple Target - https://www.tipranks.com/news/article/morgan-stanley-lifts-apple
        Published: 2026-01-01
     2. Apple Stock Forecast 2026 - https://www.tipranks.com/stocks/aapl/forecast
        Published: Not provided by source
     3. Apple Valuation Analysis - https://seekingalpha.com/article/apple-valuation
        Published: 2025-12-28
     [List ALL sources from tool response]
     
User: \"What do analysts think about Tesla?\"
You: [Call search_analyst_ratings, extract 'sources' array, display with published_date for each]

User: \"Analyze the MD&A from Tesla's recent earnings call\"
You: [Call analyze_mda_sentiment, include quarter dates]

**DATA INTEGRITY RULES:**
- Do NOT provide specific price targets, ratings, or percentages unless they come directly from tool responses
- ALWAYS cite source URL and date for every piece of financial data
- Extract 'sources' array from tool response and format each entry properly
- If a source has no published_date or it's empty, write "Not provided by source" - NEVER skip the source
- Do NOT show "Data Retrieved" timestamp or notes about missing dates - keep output clean
- Never mix data from different dates without clearly labeling each date
- Always provide full, unshortened URLs for transparency"""
    
    model = ChatOpenAI(model="gpt-4o", temperature=0)
    MCP_HTTP_STREAM_URL = "http://localhost:8567/mcp"  # Research MCP server
    
    # Keep the client and session open for the lifetime of the agent
    client = streamablehttp_client(MCP_HTTP_STREAM_URL)
    read_stream, write_stream, _ = await client.__aenter__()
    session = ClientSession(read_stream, write_stream)
    await session.__aenter__()
    await session.initialize()
    tools = await load_mcp_tools(session)
    
    agent = create_agent(
        model=model,
        tools=tools,
        name="research_agent",
        system_prompt=system_prompt,
        checkpointer=checkpointer
    )
    
    # Attach the session and client to the agent to keep them alive
    agent._mcp_session = session
    agent._mcp_client = client
    
    return agent
